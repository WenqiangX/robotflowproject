[{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"b3f5f5fa87fc5c8350517250a2687a1b","permalink":"https://wenqiangx.github.io/robotflowproject/author/cewu-lu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/cewu-lu/","section":"authors","summary":"","tags":null,"title":"Cewu Lu","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f6d2316878c097f40d3b7d8c22450434","permalink":"https://wenqiangx.github.io/robotflowproject/author/han-xue/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/han-xue/","section":"authors","summary":"","tags":null,"title":"Han Xue","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"fada9c34637f13b35e5d60a66b1faeb6","permalink":"https://wenqiangx.github.io/robotflowproject/author/haoyuan-fu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/haoyuan-fu/","section":"authors","summary":"","tags":null,"title":"Haoyuan Fu","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"173652a7e7487d2bce8acb1e23cdd369","permalink":"https://wenqiangx.github.io/robotflowproject/author/hongyang-tang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/hongyang-tang/","section":"authors","summary":"","tags":null,"title":"Hongyang Tang","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"5b010b15c0c465e2fa4919a689f44a9f","permalink":"https://wenqiangx.github.io/robotflowproject/author/huinan-yang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/huinan-yang/","section":"authors","summary":"","tags":null,"title":"Huinan Yang","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c265adf2f02c65a22a919d05d22dca76","permalink":"https://wenqiangx.github.io/robotflowproject/author/jun-lv/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/jun-lv/","section":"authors","summary":"","tags":null,"title":"Jun Lv","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"069f9f91ddc35dfec5c0f1af116c206f","permalink":"https://wenqiangx.github.io/robotflowproject/author/kailin-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/kailin-li/","section":"authors","summary":"","tags":null,"title":"Kailin Li","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9e63c1c2c785ef497d6bbac963fbc569","permalink":"https://wenqiangx.github.io/robotflowproject/author/liu-liu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/liu-liu/","section":"authors","summary":"","tags":null,"title":"Liu Liu","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6483832dae713bbf9c7e020c76fe67e7","permalink":"https://wenqiangx.github.io/robotflowproject/author/lixin-yang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/lixin-yang/","section":"authors","summary":"","tags":null,"title":"Lixin Yang","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"b9893787708fd5244e44b7427d87d00e","permalink":"https://wenqiangx.github.io/robotflowproject/author/qiaojun-yu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/qiaojun-yu/","section":"authors","summary":"","tags":null,"title":"Qiaojun Yu","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"00b56bcbcf23d9ba120f3a612432860d","permalink":"https://wenqiangx.github.io/robotflowproject/author/ruolin-ye/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/ruolin-ye/","section":"authors","summary":"","tags":null,"title":"Ruolin Ye","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4bae9db33db8ec62a04389b4e5ac0856","permalink":"https://wenqiangx.github.io/robotflowproject/author/shiyi-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/shiyi-wang/","section":"authors","summary":"","tags":null,"title":"Shiyi Wang","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"d50aa9b1fe3162310fe1cf7b7fbedb1f","permalink":"https://wenqiangx.github.io/robotflowproject/author/tutian-tang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/tutian-tang/","section":"authors","summary":"","tags":null,"title":"Tutian Tang","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"eafbf4e476228e7cfe2fddc354e25677","permalink":"https://wenqiangx.github.io/robotflowproject/author/wenqiang-xu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/wenqiang-xu/","section":"authors","summary":"","tags":null,"title":"Wenqiang Xu","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c88e139caeface1c4076f6b09b749b95","permalink":"https://wenqiangx.github.io/robotflowproject/author/wenxin-du/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/wenxin-du/","section":"authors","summary":"","tags":null,"title":"Wenxin Du","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"89580e233f62316cb64e4903ff8e990a","permalink":"https://wenqiangx.github.io/robotflowproject/author/xinyu-zhan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/xinyu-zhan/","section":"authors","summary":"","tags":null,"title":"Xinyu Zhan","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"62be3e722c573971e05d4c3f1b89f437","permalink":"https://wenqiangx.github.io/robotflowproject/author/yang-han/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/yang-han/","section":"authors","summary":"","tags":null,"title":"Yang Han","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8a85d22aaab1aeb07a4ea7c1e531790d","permalink":"https://wenqiangx.github.io/robotflowproject/author/zhendong-xue/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/robotflowproject/author/zhendong-xue/","section":"authors","summary":"","tags":null,"title":"Zhendong Xue","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://wenqiangx.github.io/robotflowproject/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/robotflowproject/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":null,"categories":null,"content":"Comming Soon.\n","date":1623542400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623542400,"objectID":"85ae8270c7041baad099123752142b09","permalink":"https://wenqiangx.github.io/robotflowproject/project/rfmove/","publishdate":"2021-06-13T00:00:00Z","relpermalink":"/robotflowproject/project/rfmove/","section":"project","summary":"A ROS-free MoveIt!","tags":["planning"],"title":"RFMove","type":"project"},{"authors":null,"categories":null,"content":"An Open-source Toolbox for 6DoF and Articulated Object Pose Annotation.\n","date":1620518400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620518400,"objectID":"3b9d6d4b679217095c793b4c7a4e5955","permalink":"https://wenqiangx.github.io/robotflowproject/project/ndpose/","publishdate":"2021-05-09T00:00:00Z","relpermalink":"/robotflowproject/project/ndpose/","section":"project","summary":"An Open-source Toolbox for 6DoF and Articulated Object Pose Annotation.","tags":["vision"],"title":"N-D Pose Annotator","type":"project"},{"authors":null,"categories":null,"content":"RFBulletT, developed by Tutian Tang, is a project which aims to provide an easy-to-use interface between Pybullet and other RobotFlow modules. As pybullet is already a highly encapsulated and easy-to-use simulator, it makes our work much easier :)\nUpon basic functionalities provided by pybullet, the RFBulletT provides more.\nFeatures  Create Environment Via Configuration File or Simple Parameter Tuning. Compatible with multiple Robot Arms, Hands, Sensors (including tactile). Domain Randomization. Gym-like interface for RL algorithms, stable baseline3 is specifically supported. Integrated Motion Planning with RFPlanner.  ","date":1620518400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620518400,"objectID":"f9eb6eee8f83a420ee10bd1c34e4519f","permalink":"https://wenqiangx.github.io/robotflowproject/project/rfbullett/","publishdate":"2021-05-09T00:00:00Z","relpermalink":"/robotflowproject/project/rfbullett/","section":"project","summary":"An Easy-to-use Simulation Environment with Pybullet.","tags":["simulation"],"title":"RFBulletT","type":"project"},{"authors":null,"categories":null,"content":"RFDigit is a modified version of Digit, which is an open-source, low-cost, high-resolution tactile sensor designed for robotic in-hand manipulation. We thank facebook research for open-sourcing the design files which makes the study of tactile modality much easier.\nIn our version, we substitute the chips in original Digit to the Chinese version which are less affected by the COVID-19 on the production delivery. Thus we also re-write the program to the chips accordingly. Besides, we manage to make the sensor thinner by altering the camera choice, without compromising the resolution of the sensor. To inherit the open-source spirit, we also make the manufacturing files of our modified version public available.\nThe simulation of RFDigit has also been integrated into RFBulletT and RFUniverse. Please refer to the document of the simulators for further details.\n","date":1620518400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620518400,"objectID":"efa80a3f20c55eefc89cf81a5da6df99","permalink":"https://wenqiangx.github.io/robotflowproject/project/rfdigit/","publishdate":"2021-05-09T00:00:00Z","relpermalink":"/robotflowproject/project/rfdigit/","section":"project","summary":"A Modified Version of Digit Tactile Sensor","tags":["hardware"],"title":"RFDigit Tactile Sensor","type":"project"},{"authors":null,"categories":null,"content":"rFUniverse is a multi-modal, physics-based, object-centric, manipulation-oriented simulation environment developed upon Unity. The reason why the naming convention is slightly different from other rf- ecosystem software is because the name of the major developer of rFUniverse project happens to be FU.\nUnity itself is a multi-purposed software, which is known for developing multiple complex games. We believe in a rather long run, it can support our need. rFUniverse is developed on ML-Agents but with significant extentions. After all, we do not aims to merely use it for RL training.\nFeatures  Create Environment Via Configuration File or Simple Parameter Tuning. Compatible with multiple Robot Arms, Hands, Sensors (including tactile). Domain Randomization. High quality rendering supported. Gym-like interface for RL algorithms, stable baseline3 is specifically supported. Integrated Motion Planning with RFPlanner. Integrated with Taichi. Multiple 3D-related tools. Realsense Camera supported. VR/AR supported.  For more details, please refer to the paper, and the code.\n","date":1620518400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620518400,"objectID":"46ae6c5b334142e2a95d87422d963189","permalink":"https://wenqiangx.github.io/robotflowproject/project/rfuniverse/","publishdate":"2021-05-09T00:00:00Z","relpermalink":"/robotflowproject/project/rfuniverse/","section":"project","summary":"A Multi-modal, Physics-based, Object-centric, Manipulation-oriented Simulation Environment Based on Unity3D.","tags":["simulation"],"title":"rFUniverse","type":"project"},{"authors":null,"categories":null,"content":"","date":1620518400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620518400,"objectID":"f413eb597ce1039af886daa6ceb93953","permalink":"https://wenqiangx.github.io/robotflowproject/project/rfvision/","publishdate":"2021-05-09T00:00:00Z","relpermalink":"/robotflowproject/project/rfvision/","section":"project","summary":"An Open-source Toolbox for Robot Vision.","tags":["vision"],"title":"RFVision","type":"project"},{"authors":null,"categories":null,"content":"Tobor Robot is an advanced dual-arm mobile manipulator with over 54 DoFs (The DoF is really just a matter of how you combine the components).\nComponents \u0026amp; Features   Head\n The head of Tobor Robot consists of an RGB-D camera. The camera on the head is mainly used for middle-range navigation. We have tested the RealSense D435 and Azure Kinect. It is safe to assume other similar choice is ok. We plan to try some other sensors to head such as thermal sensors.    Neck\n The neck is a 2-degree pan-tilt. One for pitch, one for yaw. The reason the neck doesn\u0026rsquo;t have the third roll degree is because the neck length is not long enough to make the roll actually meaningful.    Body\n The body has 2-degree. One for rise-and-fall, one for yaw. On the front of the body, we place a pad Near the back of the body, we have a backup battery.    Arm\n The arm is designed to be compatible with Flexiv Rizon (3kg) and Rokae xMate (3kg), which are both featured with 7-dof and high-precision joint force sensing. Arm-end sensors:  RGB-D cameras: we mounted RealSense D415 on both side. D415 is more accurate in the near, which is more suitable for manipulation. Force sensors: we mounted ATI force sensors on both side. The redundancy of force sensing can provide stabler readings.   Skins: Working in progress.    Hand\n We have tested multiple grippers/hands on Tobor Robot, namely Robotiq 85, AG 95, DH-3, Jodell JQ3-5, Allegro, DLR-HIT 2020 version. tactile: RFDigit.    Moving Platform\n The moving platform is Sunspeed R300.    Controllers For Tobor Robot The interface of real controllers and fake controllers (in simulation) are all natively implemented in RFController. You may refer to the corresponding document to learn how to control it.\n","date":1620518400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620518400,"objectID":"43b7a1676fd172711fa157e54360aa0c","permalink":"https://wenqiangx.github.io/robotflowproject/project/tobor_robot/","publishdate":"2021-05-09T00:00:00Z","relpermalink":"/robotflowproject/project/tobor_robot/","section":"project","summary":"An Advanced Configurable Dual-arm Mobile Manipulator.","tags":["hardware"],"title":"Tobor Robot","type":"project"},{"authors":["Ruolin Ye","Wenqiang Xu","Zhendong Xue","Tutian Tang","Yanfeng Wang","Cewu Lu"],"categories":null,"content":"","date":1619136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619136000,"objectID":"03b52704ed8c7ea614dd0f7adc2d29af","permalink":"https://wenqiangx.github.io/robotflowproject/publication/h2o/","publishdate":"2021-04-23T00:00:00Z","relpermalink":"/robotflowproject/publication/h2o/","section":"publication","summary":"A Large-scale Benchmark for Object Handover. (ICCV 2021)","tags":["hand-object, handover"],"title":"H2O: A Benchmark for Visual Human-human Object Handover Analysis","type":"publication"},{"authors":["Jun Lv","Wenqiang Xu","Lixin Yang","Sucheng Qian","Chongzhao Mao","Cewu Lu"],"categories":null,"content":"","date":1613606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613606400,"objectID":"9532251e7c3ed25ffc0d92f3c7da0d90","permalink":"https://wenqiangx.github.io/robotflowproject/publication/handtailor/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/robotflowproject/publication/handtailor/","section":"publication","summary":"A Fast and Precise Method for 3D Hand Reconstruction. (Arxiv)","tags":["hand"],"title":"HandTailor: Towards High-Precision Monocular 3D Hand Recovery","type":"publication"},{"authors":["Lixin Yang","Xinyu Zhan","Kailin Li","Wenqiang Xu","Jiefeng Li","Cewu Lu"],"categories":null,"content":"","date":1606867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606867200,"objectID":"6ddc5d1e2d8d3a88df0cad2dbca44ab3","permalink":"https://wenqiangx.github.io/robotflowproject/publication/cpf/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/robotflowproject/publication/cpf/","section":"publication","summary":"A Precise Method to Model Hand-object Interaction. (ICCV 2021)","tags":["hand-object"],"title":"CPF: Learning a Contact Potential Field to Model the Hand-object Interaction","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot;\rif porridge == \u0026quot;blueberry\u0026quot;:\rprint(\u0026quot;Eating...\u0026quot;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}}\r{{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}\r  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://wenqiangx.github.io/robotflowproject/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/robotflowproject/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"}]