<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>RobotFlow</title>
    <link>https://wenqiangx.github.io/robotflowproject/</link>
      <atom:link href="https://wenqiangx.github.io/robotflowproject/index.xml" rel="self" type="application/rss+xml" />
    <description>RobotFlow</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© 2021 Robot AI Team @ MVIG, SJTU</copyright><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>https://wenqiangx.github.io/robotflowproject/media/logo_hu46a4a8f8595a95f38f6e09503c343ee2_6156_300x300_fit_lanczos_2.png</url>
      <title>RobotFlow</title>
      <link>https://wenqiangx.github.io/robotflowproject/</link>
    </image>
    
    <item>
      <title>Example Talk</title>
      <link>https://wenqiangx.github.io/robotflowproject/talk/example-talk/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/talk/example-talk/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Wowchemy&amp;rsquo;s &lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>N-D Pose Annotator</title>
      <link>https://wenqiangx.github.io/robotflowproject/project/ndpose/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/project/ndpose/</guid>
      <description>&lt;p&gt;An Open-source Toolbox for 6DoF and Articulated Object Pose Annotation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RFBulletT</title>
      <link>https://wenqiangx.github.io/robotflowproject/project/rfbullett/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/project/rfbullett/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;#&#34;&gt;RFBulletT&lt;/a&gt;, developed by &lt;a href=&#34;#&#34;&gt;Tutian Tang&lt;/a&gt;, is a project which aims to provide an easy-to-use interface between Pybullet and other RobotFlow modules. 
As pybullet is already a highly encapsulated and easy-to-use simulator, it makes our work much easier :)&lt;/p&gt;
&lt;p&gt;Upon basic functionalities provided by pybullet, the RFBulletT provides more.&lt;/p&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Create Environment Via Configuration File or Simple Parameter Tuning.&lt;/li&gt;
&lt;li&gt;Compatible with multiple Robot Arms, Hands, Sensors (including tactile).&lt;/li&gt;
&lt;li&gt;Domain Randomization.&lt;/li&gt;
&lt;li&gt;Gym-like interface for RL algorithms, &lt;a href=&#34;https://github.com/DLR-RM/stable-baselines3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stable baseline3&lt;/a&gt; is specifically supported.&lt;/li&gt;
&lt;li&gt;Integrated Motion Planning with &lt;a href=&#34;https://github.com/WenqiangX/rfplanner&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RFPlanner&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>RFController</title>
      <link>https://wenqiangx.github.io/robotflowproject/project/rfcontroller/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/project/rfcontroller/</guid>
      <description>&lt;p&gt;Comming Soon.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RFDigit Tactile Sensor</title>
      <link>https://wenqiangx.github.io/robotflowproject/project/rfdigit/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/project/rfdigit/</guid>
      <description>&lt;p&gt;RFDigit is a modified version of &lt;a href=&#34;https://digit.ml/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Digit&lt;/a&gt;, which is an open-source, low-cost, high-resolution tactile sensor designed for robotic in-hand manipulation. We thank facebook research for open-sourcing the design files which makes the study of tactile modality much easier.&lt;/p&gt;
&lt;p&gt;In our version, we substitute the chips in original Digit to the Chinese version which are less affected by the COVID-19 on the production delivery. Thus we also re-write the program to the chips accordingly. Besides, we manage to make the sensor thinner by altering the camera choice, without compromising the resolution of the sensor. To inherit the open-source spirit, we also make the manufacturing files of our modified version public available.&lt;/p&gt;
&lt;p&gt;The simulation of RFDigit has also been integrated into &lt;a href=&#34;https://github.com/WenqiangX/rfbullett&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RFBulletT&lt;/a&gt; and &lt;a href=&#34;https://github.com/WenqiangX/rfuniverse&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RFUniverse&lt;/a&gt;. Please refer to the document of the simulators for further details.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RFMuJoCo</title>
      <link>https://wenqiangx.github.io/robotflowproject/project/rfmujoco/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/project/rfmujoco/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/WenqiangX/rfmujoco&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RFMuJoCo&lt;/a&gt;, developed by &lt;a href=&#34;https://github.com/WenqiangX&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wenqiang Xu&lt;/a&gt;, is a project which aims to provide an easy-to-use interface between MuJoCo and other RobotFlow modules.&lt;/p&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Create Environment Via Configuration File or Simple Parameter Tuning.&lt;/li&gt;
&lt;li&gt;Compatible with multiple Robot Arms, Hands, Sensors (currently not including tactile).&lt;/li&gt;
&lt;li&gt;Domain Randomization.&lt;/li&gt;
&lt;li&gt;Gym-like interface for RL algorithms, &lt;a href=&#34;https://github.com/DLR-RM/stable-baselines3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stable baseline3&lt;/a&gt; is specifically supported.&lt;/li&gt;
&lt;li&gt;Integrated Motion Planning with &lt;a href=&#34;https://github.com/WenqiangX/rfplanner&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RFPlanner&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;comments&#34;&gt;Comments&lt;/h2&gt;
&lt;p&gt;Since the MuJoCo has a really unfriendly registration machanism. The support of MuJoCo is not very active, unless we have to use MuJoCo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RFPlanner</title>
      <link>https://wenqiangx.github.io/robotflowproject/project/rfplanner/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/project/rfplanner/</guid>
      <description>&lt;p&gt;Comming Soon.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>rFUniverse</title>
      <link>https://wenqiangx.github.io/robotflowproject/project/rfuniverse/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/project/rfuniverse/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/WenqiangX/rfuniverse&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;rFUniverse&lt;/a&gt; is a multi-modal, physics-based, object-centric, manipulation-oriented simulation environment developed upon Unity. The reason why the naming convention is slightly different from other rf- ecosystem software is because the name of the major developer of rFUniverse project happens to be FU.&lt;/p&gt;
&lt;p&gt;Unity itself is a multi-purposed software, which is known for developing multiple complex games. We believe in a rather long run, it can support our need. rFUniverse is developed on ML-Agents but with significant extentions. After all, we do not aims to merely use it for RL training.&lt;/p&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Create Environment Via Configuration File or Simple Parameter Tuning.&lt;/li&gt;
&lt;li&gt;Compatible with multiple Robot Arms, Hands, Sensors (including tactile).&lt;/li&gt;
&lt;li&gt;Domain Randomization.&lt;/li&gt;
&lt;li&gt;High quality rendering supported.&lt;/li&gt;
&lt;li&gt;Gym-like interface for RL algorithms, &lt;a href=&#34;https://github.com/DLR-RM/stable-baselines3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stable baseline3&lt;/a&gt; is specifically supported.&lt;/li&gt;
&lt;li&gt;Integrated Motion Planning with &lt;a href=&#34;https://github.com/WenqiangX/rfplanner&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RFPlanner&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Integrated with &lt;a href=&#34;https://github.com/taichi-dev/taichi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Taichi&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Multiple 3D-related tools.&lt;/li&gt;
&lt;li&gt;Realsense Camera supported.&lt;/li&gt;
&lt;li&gt;VR/AR supported.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For more details, please refer to the &lt;a href=&#34;#&#34;&gt;paper&lt;/a&gt;, and the &lt;a href=&#34;https://github.com/WenqiangX/rfuniverse&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RFVision</title>
      <link>https://wenqiangx.github.io/robotflowproject/project/rfvision/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/project/rfvision/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Zen Robot</title>
      <link>https://wenqiangx.github.io/robotflowproject/project/zen_robot/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/project/zen_robot/</guid>
      <description>&lt;p&gt;Zen Robot is an advanced dual-arm mobile manipulator with over 54 DoFs (The DoF is really just a matter of how you combine the components).&lt;/p&gt;
&lt;h2 id=&#34;components--features&#34;&gt;Components &amp;amp; Features&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Head&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The head of Zen Robot consists of an RGB-D camera. The camera on the head is mainly used for middle-range navigation. We have tested the &lt;strong&gt;RealSense D435&lt;/strong&gt; and &lt;strong&gt;Azure Kinect&lt;/strong&gt;. It is safe to assume other similar choice is ok.&lt;/li&gt;
&lt;li&gt;We plan to try some other sensors to head such as thermal sensors.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Neck&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The neck is a 2-degree pan-tilt. One for pitch, one for yaw.&lt;/li&gt;
&lt;li&gt;The reason the neck doesn&amp;rsquo;t have the third roll degree is because the neck length is not long enough to make the roll actually meaningful.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Body&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The body has 2-degree. One for rise-and-fall, one for yaw.&lt;/li&gt;
&lt;li&gt;On the front of the body, we place a pad&lt;/li&gt;
&lt;li&gt;Near the back of the body, we have a backup battery.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Arm&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The arm is designed to be compatible with &lt;strong&gt;Flexiv Rizon&lt;/strong&gt; (3kg) and &lt;strong&gt;Rokae xMate&lt;/strong&gt; (3kg), which are both featured with 7-dof and high-precision joint force sensing.&lt;/li&gt;
&lt;li&gt;Arm-end sensors:
&lt;ul&gt;
&lt;li&gt;RGB-D cameras: we mounted &lt;strong&gt;RealSense D415&lt;/strong&gt; on both side. D415 is more accurate in the near, which is more suitable for manipulation.&lt;/li&gt;
&lt;li&gt;Force sensors: we mounted ATI force sensors on both side. The redundancy of force sensing can provide stabler readings.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Skins: Working in progress.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hand&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We have tested multiple grippers/hands on Zen Robot, namely &lt;a href=&#34;https://robotiq.com/products/2f85-140-adaptive-robot-gripper&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Robotiq 85&lt;/a&gt;, &lt;a href=&#34;http://en.dh-robotics.com/ag-95/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AG 95&lt;/a&gt;, &lt;a href=&#34;http://en.dh-robotics.com/dh-3/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DH-3&lt;/a&gt;, &lt;a href=&#34;http://www.jodell.cn/product/89/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jodell JQ3-5&lt;/a&gt;, &lt;a href=&#34;http://wiki.wonikrobotics.com/AllegroHandWiki/index.php/Allegro_Hand&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Allegro&lt;/a&gt;, DLR-HIT 2020 version.&lt;/li&gt;
&lt;li&gt;tactile: &lt;a href=&#34;https://wenqiangx.github.io/robotflowproject/project/rfdigit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RFDigit&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Moving Platform&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The moving platform is &lt;strong&gt;Sunspeed R300&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;controllers-for-zen-robot&#34;&gt;Controllers For Zen Robot&lt;/h2&gt;
&lt;p&gt;The interface of real controllers and fake controllers (in simulation) are all natively implemented in &lt;a href=&#34;https://github.com/WenqiangX/rfcontroller&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RFController&lt;/a&gt;.
You may refer to the corresponding document to learn how to control it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>H2O: A Benchmark for Visual Human-human Object Handover Analysis</title>
      <link>https://wenqiangx.github.io/robotflowproject/publication/h2o/</link>
      <pubDate>Fri, 23 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/publication/h2o/</guid>
      <description></description>
    </item>
    
    <item>
      <title>HandTailor: Towards High-Precision Monocular 3D Hand Recovery</title>
      <link>https://wenqiangx.github.io/robotflowproject/publication/handtailor/</link>
      <pubDate>Thu, 18 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/publication/handtailor/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CPF: Learning a Contact Potential Field to Model the Hand-object Interaction</title>
      <link>https://wenqiangx.github.io/robotflowproject/publication/cpf/</link>
      <pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/publication/cpf/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://wenqiangx.github.io/robotflowproject/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>https://wenqiangx.github.io/robotflowproject/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>https://wenqiangx.github.io/robotflowproject/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>https://wenqiangx.github.io/robotflowproject/terms/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
